{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar_100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIsPniKjtYa7",
        "colab_type": "code",
        "outputId": "deb6f380-dbce-46d9-edca-61ec63eadb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# All imports\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar100\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import h5py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZhZNOLVtbEt",
        "colab_type": "code",
        "outputId": "efd062c7-ebff-4737-bc33-b35e7cbaffe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Preparing data for training and testing NN\n",
        "num_classes = 100\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar100.h5'\n",
        "print(save_dir)\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.\n",
        "x_test /= 255.\n",
        "\n",
        "epochs = 1\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "batch_size = 64\n",
        "validations = []"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/saved_models\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAgc1B0zth_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model creation\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Conv2D(192, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(192, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "model.add(Dropout(0.15))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddIRI2UQtoBs",
        "colab_type": "code",
        "outputId": "8a7a8e2e-6b5b-4b2e-8226-b27a067ff074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Training model\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "else:\n",
        "    print('Using real-time data augmentation.')    \n",
        "for i in range(epochs):\n",
        "    if not data_augmentation:\n",
        "        model.fit(x_train, y_train,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  shuffle=True)\n",
        "    else:\n",
        "        # This will do preprocessing and realtime data augmentation:\n",
        "        datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False)  # randomly flip images\n",
        "\n",
        "        # Compute quantities required for feature-wise normalization\n",
        "        # (std, mean, and principal components if ZCA whitening is applied).\n",
        "        datagen.fit(x_train)\n",
        "\n",
        "        # Fit the model on the batches generated by datagen.flow().\n",
        "        model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                         batch_size=batch_size),\n",
        "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                            epochs=1,\n",
        "                            validation_data=(x_test, y_test))\n",
        "        validations.append(model.evaluate_generator(datagen.flow(x_test, y_test,\n",
        "                                          batch_size=batch_size),\n",
        "                                          steps=x_test.shape[0] // batch_size))\n",
        "\n",
        "pickle.dump(validations, open(\"loss_validation.p\",'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/1\n",
            "781/781 [==============================] - 47s 60ms/step - loss: 1.2615 - acc: 0.6494 - val_loss: 1.4905 - val_acc: 0.6067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg7hihsEtuXG",
        "colab_type": "code",
        "outputId": "af7e6b44-d8cd-452d-b41a-5b19d3a675fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Predictions of model\n",
        "label_list_path = 'datasets/cifar-100-python/meta'\n",
        "\n",
        "keras_dir = os.path.expanduser(os.path.join('~', '.keras'))\n",
        "datadir_base = os.path.expanduser(keras_dir)\n",
        "if not os.access(datadir_base, os.W_OK):\n",
        "    datadir_base = os.path.join('/tmp', '.keras')\n",
        "label_list_path = os.path.join(datadir_base, label_list_path)\n",
        "\n",
        "with open(label_list_path, mode='rb') as f:\n",
        "    labels = pickle.load(f)\n",
        "\n",
        "# Evaluate model with test data set and share sample prediction results\n",
        "evaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n",
        "                                      batch_size=batch_size),\n",
        "                                      steps=x_test.shape[0] // batch_size)\n",
        "\n",
        "print('Model Accuracy = %.2f' % (evaluation[1]))\n",
        "\n",
        "predict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n",
        "                                      batch_size=batch_size),\n",
        "                                      steps=x_test.shape[0] // batch_size)\n",
        "\n",
        "for predict_index, predicted_y in enumerate(predict_gen):\n",
        "    actual_label = labels['fine_label_names'][np.argmax(y_test[predict_index])]\n",
        "    predicted_label = labels['fine_label_names'][np.argmax(predicted_y)]\n",
        "    print('Actual Label = %s vs. Predicted Label = %s' % (actual_label,\n",
        "                                                          predicted_label))\n",
        "    if predict_index == num_predictions:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy = 0.60\n",
            "Actual Label = mountain vs. Predicted Label = pear\n",
            "Actual Label = forest vs. Predicted Label = wardrobe\n",
            "Actual Label = seal vs. Predicted Label = man\n",
            "Actual Label = mushroom vs. Predicted Label = keyboard\n",
            "Actual Label = sea vs. Predicted Label = elephant\n",
            "Actual Label = tulip vs. Predicted Label = pear\n",
            "Actual Label = camel vs. Predicted Label = kangaroo\n",
            "Actual Label = butterfly vs. Predicted Label = woman\n",
            "Actual Label = cloud vs. Predicted Label = motorcycle\n",
            "Actual Label = apple vs. Predicted Label = maple_tree\n",
            "Actual Label = sea vs. Predicted Label = skyscraper\n",
            "Actual Label = skunk vs. Predicted Label = orchid\n",
            "Actual Label = streetcar vs. Predicted Label = cloud\n",
            "Actual Label = rocket vs. Predicted Label = pear\n",
            "Actual Label = lamp vs. Predicted Label = woman\n",
            "Actual Label = lion vs. Predicted Label = couch\n",
            "Actual Label = tulip vs. Predicted Label = cup\n",
            "Actual Label = wolf vs. Predicted Label = bowl\n",
            "Actual Label = rose vs. Predicted Label = dolphin\n",
            "Actual Label = orange vs. Predicted Label = mushroom\n",
            "Actual Label = rose vs. Predicted Label = man\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR-y9D4gdCYt",
        "colab_type": "code",
        "outputId": "990ecd77-1350-4dc1-ec62-698d8b60e84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# Some test dump to see how model works\n",
        "x = np.random.randint(0,len(x_test))\n",
        "prediction = np.argmax(model.predict(np.array([x_test[x]])))\n",
        "actual = np.argmax(y_test[x])\n",
        "print(prediction)\n",
        "print(actual)\n",
        "print(labels['fine_label_names'][prediction])\n",
        "print(labels['fine_label_names'][actual])\n",
        "plt.imshow(x_test[x])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94\n",
            "94\n",
            "wardrobe\n",
            "wardrobe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb5361cb160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf1DmDMQ7WIBSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dezu8A-srZHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}